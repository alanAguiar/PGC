{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import copy\n",
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chromossome:\n",
    "    def __init__(self, algorithm, random_state=None, **hyperparameter_range):\n",
    "        self.hyperparameter_range = hyperparameter_range\n",
    "        try:\n",
    "            self.classifier = algorithm(random_state=random_state)\n",
    "        except:\n",
    "            self.classifier = algorithm()\n",
    "        self.mutate()\n",
    "        self.fitness = 0\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        is_fitted = True\n",
    "        self.classifier.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "    \n",
    "    def check_is_fitted(self):\n",
    "        return self.is_fitted\n",
    "    \n",
    "    def mutate(self, n_positions=None):\n",
    "        param = {}        \n",
    "        if not n_positions or n_positions>len(self.hyperparameter_range):\n",
    "            n_positions = len(self.hyperparameter_range)\n",
    "        mutation_positions = random.sample(range(0, len(self.hyperparameter_range)), n_positions)\n",
    "        i = 0\n",
    "        for hyperparameter, h_range in self.hyperparameter_range.items():\n",
    "            if i in mutation_positions:\n",
    "                if isinstance(h_range[0], str):\n",
    "                    param[hyperparameter] = random.choice(h_range)\n",
    "                elif isinstance(h_range[0], float):\n",
    "                    param[hyperparameter] = random.uniform(h_range[0], h_range[1]+1)\n",
    "                else:\n",
    "                    param[hyperparameter] = random.randint(h_range[0], h_range[1]+1)\n",
    "            i+= 1\n",
    "        \n",
    "        self.classifier.set_params(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DiversityEnsembleClassifier:\n",
    "    def __init__(self, algorithms, population_size = 100, max_epochs = 100, random_state=None):\n",
    "        self.population_size = population_size\n",
    "        self.max_epochs = max_epochs\n",
    "        self.population = []\n",
    "        self.random_state = random_state\n",
    "        for algorithm, hyperparameters in algorithms.items():\n",
    "            for i in range(0, math.ceil(population_size/len(algorithms.keys()))):\n",
    "                self.population.append(Chromossome(algorithm, random_state=random_state, **hyperparameters))\n",
    "    \n",
    "    def generate_offspring(self):\n",
    "        for i in range(0, self.population_size):\n",
    "            new_chromossome = copy.deepcopy(self.population[i])\n",
    "            new_chromossome.mutate(1)\n",
    "            self.population.append(new_chromossome)\n",
    "            \n",
    "    def fit_predict_population(self, kfolds, X, y):\n",
    "        predictions = np.empty([2*self.population_size, y.shape[0]])\n",
    "        for i in range(2*self.population_size):\n",
    "            chromossome = self.population[i]\n",
    "            for train, val in kfolds.split(X):\n",
    "                if not chromossome.check_is_fitted(): chromossome.fit(X[train], y[train])\n",
    "                predictions[i][val] = np.equal(chromossome.predict(X[val]), y[val])\n",
    "        return predictions \n",
    "    \n",
    "    def diversity_selection(self, predictions):\n",
    "        distances = np.zeros(2*self.population_size)\n",
    "        pop_fitness = predictions.sum(axis=1)\n",
    "        target_chromossome = np.argmin(pop_fitness)\n",
    "        new_population = []            \n",
    "        selected = [target_chromossome]\n",
    "        diversity  = np.zeros(2*self.population_size)\n",
    "        for i in range(0, self.population_size-1):\n",
    "            distances[target_chromossome] = float('-inf')\n",
    "            d_i = np.logical_xor(predictions, predictions[target_chromossome]).sum(axis=1)\n",
    "            distances += d_i\n",
    "            diversity += d_i\n",
    "            target_chromossome = np.argmax(distances)\n",
    "            selected.append(target_chromossome)\n",
    "            self.population[target_chromossome].fitness = pop_fitness[target_chromossome]\n",
    "        for x in selected:\n",
    "            new_population.append(self.population[x]) \n",
    "        print(diversity[selected].sum())\n",
    "        return new_population\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        print('Running epoch ', end='')        \n",
    "        kf = KFold(n_splits=5, random_state=self.random_state)      \n",
    "        \n",
    "        for epoch in range(self.max_epochs):             \n",
    "            print(epoch, end='...')            \n",
    "            self.generate_offspring()                \n",
    "            predictions = self.fit_predict_population(kf, X, y)            \n",
    "            self.population = self.diversity_selection(predictions)\n",
    "            \n",
    "        for chromossome in self.population:\n",
    "            chromossome.fit(X, y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = np.empty((self.population_size, len(X)))\n",
    "        y = np.empty(len(X))\n",
    "        for chromossome in range(0, self.population_size):\n",
    "            predictions[chromossome] = self.population[chromossome].predict(X)\n",
    "        for i in range(0, len(X)):\n",
    "            pred = {}\n",
    "            for j in range(0, self.population_size):\n",
    "                if predictions[j][i] in pred:\n",
    "                    pred[predictions[j][i]] += self.population[j].fitness\n",
    "                else: \n",
    "                    pred[predictions[j][i]]  = self.population[j].fitness\n",
    "            y[i] = max(pred.items(), key=operator.itemgetter(1))[0]\n",
    "        return y\n",
    "        \"\"\"\n",
    "        predictions = np.empty([self.population_size, X.shape[0]])\n",
    "        for i in range(0, self.population_size):\n",
    "            predictions[i] = self.population[i].predict(X)\n",
    "        return scipy.stats.mode(predictions, axis=0).mode[0]\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 0...123773.0\n",
      "1...126653.0\n",
      "2...128511.0\n",
      "3...130551.0\n",
      "4...131607.0\n",
      "5...131848.0\n",
      "6...132259.0\n",
      "7...132845.0\n",
      "8...133965.0\n",
      "9...134682.0\n",
      "10...134736.0\n",
      "11...134736.0\n",
      "12...134843.0\n",
      "13...134935.0\n",
      "14...135094.0\n",
      "15...135094.0\n",
      "16...135094.0\n",
      "17...135377.0\n",
      "18...135621.0\n",
      "19...135621.0\n",
      "20...135826.0\n",
      "21...136170.0\n",
      "22...136304.0\n",
      "23...136304.0\n",
      "24...136394.0\n",
      "25...136553.0\n",
      "26...136559.0\n",
      "27...136559.0\n",
      "28...136559.0\n",
      "29...136559.0\n",
      "30...136559.0\n",
      "31...136822.0\n",
      "32...136988.0\n",
      "33...137018.0\n",
      "34...137079.0\n",
      "35...137079.0\n",
      "36...137079.0\n",
      "37...137079.0\n",
      "38...137079.0\n",
      "39...137086.0\n",
      "40...137086.0\n",
      "41...137086.0\n",
      "42...137086.0\n",
      "43...137159.0\n",
      "44...137159.0\n",
      "45...137159.0\n",
      "46...137159.0\n",
      "47...137159.0\n",
      "48...137159.0\n",
      "49...137222.0\n",
      "50...137222.0\n",
      "51...137243.0\n",
      "52...137243.0\n",
      "53...137243.0\n",
      "54...137243.0\n",
      "55...137243.0\n",
      "56...137231.0\n",
      "57...137236.0\n",
      "58...137237.0\n",
      "59...137237.0\n",
      "60...137237.0\n",
      "61...137237.0\n",
      "62...137237.0\n",
      "63...137237.0\n",
      "64...137237.0\n",
      "65...137237.0\n",
      "66...137237.0\n",
      "67...137237.0\n",
      "68...137237.0\n",
      "69...137237.0\n",
      "70...137237.0\n",
      "71...137237.0\n",
      "72...137237.0\n",
      "73...137237.0\n",
      "74...137237.0\n",
      "75...137240.0\n",
      "76...137240.0\n",
      "77...137240.0\n",
      "78...137240.0\n",
      "79...137240.0\n",
      "80...137240.0\n",
      "81...137240.0\n",
      "82...137240.0\n",
      "83...137240.0\n",
      "84...137240.0\n",
      "85...137240.0\n",
      "86...137240.0\n",
      "87...137240.0\n",
      "88...137240.0\n",
      "89...137240.0\n",
      "90...137240.0\n",
      "91...137240.0\n",
      "92...137240.0\n",
      "93...137240.0\n",
      "94...137240.0\n",
      "95...137240.0\n",
      "96...137240.0\n",
      "97...137240.0\n",
      "98...137240.0\n",
      "99...137240.0\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "alg = {\n",
    "            KNeighborsClassifier: {'n_neighbors':[1, 107]},\n",
    "            SVC: {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "                  'degree' : [0, 3]\n",
    "                  },\n",
    "            DecisionTreeClassifier: {'min_samples_leaf':[1, 100], 'max_depth':[3, 20]},\n",
    "            RandomForestClassifier: {'min_samples_leaf':[1, 100], 'max_depth':[3, 20],\n",
    "                                     'n_estimators':[100, 100]},\n",
    "            GaussianNB: {},\n",
    "            LinearDiscriminantAnalysis: {}\n",
    "    \n",
    "      }\n",
    "dec = DiversityEnsembleClassifier(alg, population_size=50, max_epochs=100, random_state=42)\n",
    "dec.fit(X_train,  y_train)\n",
    "print(accuracy_score(y_test, dec.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=87, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=32, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=55, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
      "           weights='uniform'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=65, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=52, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
      "           weights='uniform'), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=32, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=1, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=21, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=47, p=2,\n",
      "           weights='uniform'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=71, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=101, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=53, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=32, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
      "           weights='uniform'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=49, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=101, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=32, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'), RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=46, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "#Inspect the classifiers\n",
    "print([x.classifier for x in dec.population])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check number of unique classifiers\n",
    "unique = set([str(x.classifier.get_params()) for x in dec.population])\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.empty()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
